{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOInSZfcuaUf5f12ylvzi95",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yuukionna022/Computer-Vision-Project/blob/main/FontDetection_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run All Blocks Before Using"
      ],
      "metadata": {
        "id": "VoKhmOFSVedn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cp2Pw7DhUs8x"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import cv2\n",
        "import seaborn as sns\n",
        "import glob\n",
        "import xml.etree.ElementTree as ET\n",
        "from PIL import Image\n",
        "import os\n",
        "import shutil"
      ],
      "metadata": {
        "id": "QiGGbub9U3al"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install ultralytics\n",
        "import ultralytics\n",
        "ultralytics.checks()\n",
        "from ultralytics import YOLO"
      ],
      "metadata": {
        "id": "dxOFeRA1U4oF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_outer(obb_data, w, h):\n",
        "  x_min, y_min = w, h\n",
        "  x_max, y_max = 0, 0\n",
        "\n",
        "  for point in obb_data:\n",
        "    x, y = point\n",
        "    x_min = min(x_min, x)\n",
        "    y_min = min(y_min, y)\n",
        "    x_max = max(x_max, x)\n",
        "    y_max = max(y_max, y)\n",
        "\n",
        "  return int(x_min), int(y_min), int(x_max), int(y_max)\n",
        "\n",
        "def overlapping(box1, box2):\n",
        "  x1_min, y1_min = box1[0]\n",
        "  x1_max, y1_max = box1[1]\n",
        "\n",
        "  x2_min, y2_min = box2[0]\n",
        "  x2_max, y2_max = box2[1]\n",
        "\n",
        "  if(x1_min < x2_max and x1_max > x2_min) and (y1_min < y2_max and y1_max > y2_min):\n",
        "    return True\n",
        "\n",
        "  return False\n",
        "\n",
        "def merge(boxes):\n",
        "  merged_boxes = []\n",
        "\n",
        "  while boxes:\n",
        "    # remove first box from the list and process it\n",
        "    box1 = boxes.pop(0)\n",
        "    merged = False\n",
        "\n",
        "    for i, box2 in enumerate(boxes):\n",
        "      if(overlapping(box1, box2)):\n",
        "        x1_min, y1_min = box1[0]\n",
        "        x1_max, y1_max = box1[1]\n",
        "\n",
        "        x2_min, y2_min = box2[0]\n",
        "        x2_max, y2_max = box2[1]\n",
        "\n",
        "        # new box\n",
        "        box = [\n",
        "            (min(x1_min, x2_min), min(y1_min, y2_min)),\n",
        "            (max(x1_max, x2_max), min(y1_max, y2_max)),\n",
        "        ]\n",
        "\n",
        "        boxes[i] = box\n",
        "        merged = True\n",
        "        break\n",
        "    if not merged:\n",
        "      merged_boxes.append(box1)\n",
        "\n",
        "  return merged_boxes\n",
        "\n",
        "def crop_img(img, boxes, w, h):\n",
        "  cropped_imgs = []\n",
        "\n",
        "  for box in boxes:\n",
        "    (x_min, y_min), (x_max, y_max) = box\n",
        "\n",
        "    threshold = 8\n",
        "    x_min -= threshold\n",
        "    y_min -= threshold\n",
        "    x_max += threshold\n",
        "    y_max += threshold\n",
        "\n",
        "    x_min = max(0, x_min)\n",
        "    y_min = max(0, y_min)\n",
        "    x_max = min(w, x_max)\n",
        "    y_max = min(h, y_max)\n",
        "\n",
        "    cropped_img = img[int(y_min):int(y_max), int(x_min):int(x_max)]\n",
        "    cropped_imgs.append(cropped_img)\n",
        "\n",
        "  return cropped_imgs\n",
        "\n",
        "def scale(file_paths, output_folder, size):\n",
        "  scaled_image_paths = []\n",
        "\n",
        "  for file_dir in file_paths:\n",
        "    file_name = os.path.basename(file_dir)\n",
        "    output_path = os.path.join(output_folder, file_name)\n",
        "\n",
        "    with Image.open(file_dir) as img:\n",
        "      img_resized = img.resize(size)\n",
        "      img_resized.save(output_path)\n",
        "      scaled_image_paths.append(output_path)\n",
        "\n",
        "  return scaled_image_paths\n",
        "\n",
        "def identify_font(img_path, scale_img):\n",
        "  #combined piece of code to get cropped images and list of their paths\n",
        "  #get the predicted boxes\n",
        "  results = det_model(img_path)\n",
        "  #get the coordinates of the bounding boxes\n",
        "  obss = results[0].obb.xyxyxyxy.tolist()\n",
        "  #load the original image\n",
        "  image_path = results[0].path\n",
        "  image = cv2.imread(image_path)\n",
        "  #get the width and height of the image\n",
        "  width = image.shape[1]\n",
        "  height = image.shape[0]\n",
        "  #get the image name\n",
        "  name = os.path.splitext(os.path.basename(img_path))[0]\n",
        "  #create a list of the all the bounding box coordinates\n",
        "  coords = []\n",
        "  #go through the bounding boxes and find the top left, and bottom right coordinate\n",
        "  for i, bbox in enumerate(obss):\n",
        "    x_min, y_min, x_max, y_max = get_outer(bbox, width, height)\n",
        "    coords.append([(x_min, y_min), (x_max, y_max)])\n",
        "  #merge bounding boxes that overlap\n",
        "  merged = merge(coords)\n",
        "  #get the coordinates to crop the image\n",
        "  cropped = crop_img(image, merged, width, height)\n",
        "  #list to keep file paths to feed into next model\n",
        "  all_img_paths = []\n",
        "  #creating the files\n",
        "  for i, cropped_img in enumerate(cropped):\n",
        "    os.makedirs('/content/Cropped Images/', exist_ok=True)\n",
        "    cv2.imwrite('/content/Cropped Images/' + name + f'_{i}.jpg', cropped_img)\n",
        "    all_img_paths.append('/content/Cropped Images/' + name + f'_{i}.jpg')\n",
        "    print(\"Created cropped file: \" + '/content/Cropped Images/' + name + f'_{i}.jpg')\n",
        "\n",
        "  if scale_img:\n",
        "    output_dir = \"/content/Resized Images\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    size = (640,640)\n",
        "    scaled_images_paths = scale(all_img_paths, output_dir, size)\n",
        "\n",
        "    for font_img in scaled_images_paths:\n",
        "      clsmodel.predict(font_img, imgsz= (256, 640), save = True)\n",
        "  else:\n",
        "    for font_img in all_img_paths:\n",
        "      clsmodel.predict(font_img, imgsz= (256, 640))"
      ],
      "metadata": {
        "id": "XBifpCnLU7AM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#download \"thefinalmodel.pt\" and replace the file path\n",
        "det_model = YOLO(\"/content/drive/MyDrive/Final Project Transferred/thefinalmodel.pt\")"
      ],
      "metadata": {
        "id": "Z8lUrhf6U8h1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#download \"classmodel.pt\" and replace the file path\n",
        "clsmodel = YOLO(\"/content/drive/MyDrive/Final Project Transferred/classmodel.pt\")"
      ],
      "metadata": {
        "id": "teEWJnuHU9tl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final use testing"
      ],
      "metadata": {
        "id": "laeTA_W1U_y1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#input file path, set true if want to scale before predicting, false otherwise (false works better)\n",
        "identify_font(\"/content/drive/MyDrive/IAT 360/Computer Vision Project/test/BrushScriptMT/BrushscriptMT$$test_1.png\", False)"
      ],
      "metadata": {
        "id": "VFwGyxAhVBwd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Image.open(\"/content/Cropped Images/BrushscriptMT$$test_1_0.jpg\")"
      ],
      "metadata": {
        "id": "DPsa5RP3VD-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Image.open(\"/content/Cropped Images/BrushscriptMT$$test_1_1.jpg\")"
      ],
      "metadata": {
        "id": "NJqWof7QVFGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Image.open(\"/content/Cropped Images/BrushscriptMT$$test_1_2.jpg\")"
      ],
      "metadata": {
        "id": "e4DBkIftVGPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Image.open(\"/content/Cropped Images/BrushscriptMT$$test_1_3.jpg\")"
      ],
      "metadata": {
        "id": "KYSzxT9mVHhl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Image.open(\"/content/drive/MyDrive/IAT 360/Computer Vision Project/test/BrushScriptMT/BrushscriptMT$$test_1.png\")"
      ],
      "metadata": {
        "id": "Gs5JVUAkVI59"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#www.reddit.com/r/FaithNoMore/comments/1exsaum/forgot_i_had_these_posters_only_1_was_ever_hung/#lightbox images from here\n",
        "identify_font(\"/content/drive/MyDrive/Final Project Transferred/Testing Images/redditimg1.png\", False)"
      ],
      "metadata": {
        "id": "pFLp38SdVLNl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Image.open(\"/content/drive/MyDrive/Final Project Transferred/Testing Images/redditimg1.png\")"
      ],
      "metadata": {
        "id": "6vFgOF8EVMUO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Image.open(\"/content/Cropped Images/redditimg1_0.jpg\")"
      ],
      "metadata": {
        "id": "Hf6RQi8PVN1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "identify_font(\"/content/drive/MyDrive/Final Project Transferred/Testing Images/redditimg2.png\", False)"
      ],
      "metadata": {
        "id": "5bezICyOVPQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Image.open(\"/content/drive/MyDrive/Final Project Transferred/Testing Images/redditimg2.png\")"
      ],
      "metadata": {
        "id": "OYFIx5o9VQie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Image.open(\"/content/Cropped Images/redditimg2_0.jpg\")"
      ],
      "metadata": {
        "id": "iL7f5OjzVR82"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "identify_font(\"/content/drive/MyDrive/Final Project Transferred/Testing Images/redditimg3.png\", False)"
      ],
      "metadata": {
        "id": "Cprsw1rBVTMl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Image.open(\"/content/drive/MyDrive/Final Project Transferred/Testing Images/redditimg3.png\")"
      ],
      "metadata": {
        "id": "jaf3w6yeVUXO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Image.open(\"/content/Cropped Images/redditimg3_0.jpg\")"
      ],
      "metadata": {
        "id": "5rBuLSORVVj9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Image.open(\"/content/Cropped Images/redditimg3_1.jpg\")"
      ],
      "metadata": {
        "id": "aY3qUou0VW5V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}